{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nc6TuMX5qHnD"
      },
      "outputs": [],
      "source": [
        "class LineModel:\n",
        "    def __init__(self, slope=1.0, bias=0.0):\n",
        "        self.slope = slope\n",
        "        self.bias = bias\n",
        "        self.points = []\n",
        "\n",
        "    def add_point(self, x, y):\n",
        "        self.points.append((x, y))\n",
        "\n",
        "    def clear_points(self):\n",
        "        self.points = []\n",
        "\n",
        "    def calculate_perpendicular_distance(self, x, y):\n",
        "        # Calculate perpendicular distance from point (x, y) to the line y = slope*x + bias\n",
        "        numerator = abs(self.slope * x - y + self.bias)\n",
        "        denominator = (self.slope**2 + 1)**0.5\n",
        "        return numerator / denominator\n",
        "class OptimizeLineModel(LineModel):\n",
        "    def __init__(self, slope=1.0, bias=0.0):\n",
        "        super().__init__(slope, bias)\n",
        "\n",
        "    def optimize_line(self, learning_rate=0.01, max_iterations=1000, tolerance=1e-6):\n",
        "        # Initialize variables\n",
        "        iteration = 0\n",
        "        prev_slope = self.slope\n",
        "        prev_bias = self.bias\n",
        "        num_points = len(self.points)\n",
        "\n",
        "        while iteration < max_iterations:\n",
        "            gradient_slope = 0.0\n",
        "            gradient_bias = 0.0\n",
        "\n",
        "            # Compute gradients\n",
        "            for (x, y) in self.points:\n",
        "                distance = self.calculate_perpendicular_distance(x, y)\n",
        "                sign = 1.0 if (self.slope * x + self.bias - y) >= 0 else -1.0\n",
        "                gradient_slope += sign * (x * (self.slope**2 + 1)**0.5 - y * self.slope) / num_points\n",
        "                gradient_bias += sign * (self.slope - (y - self.bias) / x) / num_points\n",
        "\n",
        "            # Update parameters\n",
        "            self.slope -= learning_rate * gradient_slope\n",
        "            self.bias -= learning_rate * gradient_bias\n",
        "\n",
        "            # Check convergence\n",
        "            if abs(self.slope - prev_slope) < tolerance and abs(self.bias - prev_bias) < tolerance:\n",
        "                break\n",
        "\n",
        "            # Update iteration and previous values\n",
        "            iteration += 1\n",
        "            prev_slope = self.slope\n",
        "            prev_bias = self.bias\n",
        "\n",
        "        if iteration == max_iterations:\n",
        "            print(\"Optimization did not converge within the maximum number of iterations.\")\n",
        "\n",
        "    def fit(self):\n",
        "        # Placeholder method for potential further refinement or actions after optimization\n",
        "        pass\n",
        "  line = OptimizeLineModel()\n",
        "  line.add_point(1, 2)\n",
        "  line.add_point(2, 3)\n",
        "  line.add_point(3, 4)\n",
        "\n",
        "  print(f\"Initial slope: {line.slope}, Initial bias: {line.bias}\")\n",
        "\n",
        "  line.optimize_line()\n",
        "\n",
        "  print(f\"Optimized slope: {line.slope}, Optimized bias: {line.bias}\")"
      ]
    }
  ]
}